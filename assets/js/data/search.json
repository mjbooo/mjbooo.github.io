[ { "title": "Model review: Structured Denoising Diffusion Models in Discrete State-Space (Ho et al., 2021)", "url": "/posts/Structured-Denoising-Diffusion-Models-in-Discrete-State-Space-(Ho-et-al.,-2021)/", "categories": "AI, Diffusion model", "tags": "Generative model, Diffusion model, review, D3PM, Discrete State Space, DDPM in Discrete State-Space", "date": "2022-09-20 14:00:00 +0900", "snippet": "Introcontinuous state-space를 다루던 DDPM을 discrete state space에서 작동하게 만든 것이 D3PM이다.때문에 DDPM과 비유를 통했을 때(특히 Jonathan Ho가 논문에 참여한만큼) 훨씬 수월하게 이해할 수 있다.One-sentence Summary kor: 기존 Multinomial diffusion model을 generalize시킴으로써 discrete state space에서 더 잘 작동하게 된 diffusion model (D3PM)을 선보인 논문 en: Introducing Discrete Denoising Diffusion Probabilistic Model (D3PM) which works better in discrete state space as it generalizes the existing multinomial diffusion model A link for the paper: https://openreview.net/forum?id=h7-XixPCAL The PPT file I made for the review: 220920_Structured Denoising Diffusion Models in Discrete State-SpaceAnalogy with DDPM Denoising Diffusion Probabilistic Model (Ho et al., 2020)Intro에서 언급DDPM: Gaussian kernel (continuous space)-&gt; known stationary distribution D3PM: Transition matrix (discrete space)-&gt; known stationary distributionforward를 단계적으로 할 필요는 없이, 전체 timestep 1..T 중 arbitrary t를 sampling할 수 있다.   state-space diffuses input with converges to according to forwards by t with model outputs (reverse) D3PM discrete Transition Matrix (Multinomial dist.) stationary dist. Markov chain cumulative product t-step reverse DDPM continuous Gaussian Kernel (Gaussian dist.) stationary dist. (Gaussian) noise schedule noise schedule 1-step reverse Forward Processforward process를 표로 간단하게 도식화해보자면,   sampling (stochasticity) with according to.. DDPM Gaussian dist. noise schedule D3PM Multinomial dist. Markov chain still writing.." }, { "title": "Model review: Classifier-Free Diffusion Guidance (Ho et al., 2021)", "url": "/posts/Classifier-Free-Diffusion-Guidance-(Ho-et-al.,-2021)/", "categories": "AI, Diffusion model", "tags": "Generative model, Diffusion model, review, Classifier-Free Guidance, Classifier Guidance", "date": "2022-07-29 14:00:00 +0900", "snippet": "Introgradient를 이용한 guidance나 truncation trick에 익숙하면 논문의 취지를 쉽게 파악할 수 있다.One-sentence Summary kor: Diffusion Models Beat GANs on Image Synthesis에서 수행한 classifier-guidance를 pre-trained classifier 없이도 (classifier-free) 수행할 수 있음을 보인 논문 en: Introducing classifier-free guidance performing classifier-guidance without the pre-trained classifier, necessitated in previous paper ‘Diffusion Models Beat GANs on Image Synthesis’ A link for the paper: https://openreview.net/forum?id=qw8AKxfYbI The PPT file I made for the review: 220516classifier_free_guidance mj.pdfClassifier Guidance Diffusion Models Beat GANs on Image Synthesis (Dhariwalet al., 2021)Classifier-Free Guidance가 있으면, 그냥 Guidance도 있지 않을까?그걸 다룬 것이 Dhariwalet al., 2021 논문이다.classifier-guidance를 통해 fidelity와 diversity를 trade-off 시킬 수 있고, 그렇게 하면 fidelity 측면에서 diffusion model이 GAN 모델 중 SOTA인 BigGAN을 이긴다는 내용이다. Diffusion model과 score-based model의 관계DDPM (Denoising Diffusion Probabilistic Models) 논문의 의의는 근본 diffusion model을 제시한 것에 그치지 않는다.diffusion model과 score-based model의 내재적 연결성을 밝힌 것이 또다른 중요한 의의이다.다시말해, 원본 데이터와 timestep, epsilon을 샘플링해서 ($X_0\\sim D$, timestep $t\\sim T$, $\\epsilon \\sim N$ $X_t$를 만들고 그것으로 $\\hat{\\epsilon} (X_t, t)$를 output했을 때, 그 output $\\hat{\\epsilon}$ 가 score-function, 즉 gradients of log probability density functions이라는 것이다. 그 관계가 왜 중요한가?이 점을 알고나면, classifier-guidance에서 왜 난데없이 diffusion model output $\\hat{\\epsilon}$ ${(z_{\\lambda},c)}$에 score-function인 $\\nabla_{z_{\\lambda}} \\log p_{\\theta} (c|z_{\\lambda})$ 를 더해버리는지 알 수 있다.위에서 언급한 관계에 의하면 사실 둘은 같은 개념이기 때문에 weighted sum (by $w$) 할 수 있었던 것이다!따라서 위 식의 흐름을 말로 풀어보면, 원래 diffusion model로 생성한 vector field에 classifier로 만든 vector field를 더해주어 원하는 class로 guide할 수 있고, 그 guide하는 정도는 weight $w$에 의해 조절된다고 할 수 있다.Classifier-‘Free’ Guidance Classifier-‘Free’ Guidance의 필요성그럼 왜 Classifier-‘free’ Guidance가 필요할까?classifier-guidance는 noised data로 학습한 pre-trained classfier가 필요한데, 이게 data pipeline을 복잡하게 만든다.또 (저자들의 주장에 따르면) noised data를 사용한 것이 adversarial attack을 일으켜 성능 저하를 일으킨다.그래서 이 논문은 classifier 없이 순수하게 generative model만 이용해서 guidance를 주는 방법을 택했다.물론 그 대가로 sampling speed가 느려질 수 있는데, 보통 classifier보다 generative model이 크기 때문에 forward가 느려서 그렇다. Training &amp; Inference in Classifier-Free Guidance한 diffusion model을 (DDPM처럼 backbone은 U-net)을 train할 때– class-conditional은 특정 class로 condition을 준 후 학습하고– class-unconditional은 class를 random으로 섞어서 학습하고학습 후 inference할 때, conditional과 unconnditional의 output $\\hat{\\epsilon}$ ${(z_{\\lambda},c)}$, $\\hat{\\epsilon}$ ${(z_{\\lambda})}$ 을 weighted sum 한다! Classifier-Free Guidance 식으로 이해하기식이 보여주는 큰 흐름을 먼저 짚자면, 기존 classifier guidance식의 guidance term을 pre-trained classifier 없이 generative model의 output $\\epsilon$만으로 나타낼 수 있다는 것이다.– implicit classifier: classifier가 별도로 있는 것은 아니지만, 개념적으로 implicit한 classifier를 생각해보면 bayes rule을 이용해서 score function을 구할 수 있다. 거기에 DDPM에서 밝힌 내재적 연관성을 얹으면 implicit classifier로부터 구한 score function은 conditional과 unconditinal model의 output $\\epsilon_{\\theta} (z_{\\lambda}, c)$ 와 $\\epsilon_{\\theta} (z_{\\lambda})$ 으로 표현된다.– Classifier-Free guidance: 그럼 implicit classifier의 score function을 classifier guidance의 score function 식에 그대로 대입하면 $\\tilde\\epsilon_{\\theta} (z_{\\lambda}, c)$ 는 $\\epsilon_{\\theta} (z_{\\lambda}, c)$ 와 $\\epsilon_{\\theta} (z_{\\lambda})$ 의 Linear combination, 즉 conditional과 unconditional model outputs를 Linear combination한 값이 된다. 그렇기에 학습해둔 model에서 sampling (inference) 할 때도 condition을 줘서 한번, condition 주지 않고 한번 output을 뽑아서 linear combination하는 것이다.이때 cond 와 uncond의 차이를 $w$로 scaling해주기 떄문에 weight $w$를 세게 주면 class 정보가 더 세게, 즉 condition과 uncondition의 차이가 강조되는 것으로 해석할 수 있다.이는 곧 guidance를 세게 주는 것과 마찬가지이다. sidenote: $\\epsilon$ 에 별을 붙여서 $\\epsilon^*$로 나타낸 이유?논문에 ‘If we had access to exact scores …‘라는 표현이 나온다.Discussion 파트에 보면, ‘Our diffusion models are parameterized by unconstrained neural networks and therefore their score estimates do not necessarily form conservative vector fields, unlike classifier gradients’라는 구절이 나온다.뭔 소린지는 좀더 봐야 제대로 이해할 것 같지만… conservative vector field가 있어야만 classifier log likelihood 같은 scalar potential이 존재한다는 것을 보장할 수 있나보다.classifier-guidance에서는 diffusion model과 완전히 분리된 pre-trained classifier의 gradient를 쓴다.그런데 classifier-free guidance에서는 unconstrained neural net을 썼기 때문에, model의 output인 score estimates가 non-conservative한 vector field이다.따라서 보통 classifier log likelihood 같은 scalar potential이 존재하지 않는다.이는 곧 위에서 언급한 $\\epsilon_{\\theta} (z_{\\lambda}, c)$ 와 $\\epsilon_{\\theta} (z_{\\lambda})$의 Linear combination을 classifier guided score로 가지는 classifier가 보통 존재하지 않는다는 소리이다.이론적으로는 그렇지만, 경험적으로 봤을 때는 implicit classifier 가정이 잘 먹히고 실험적으로도 증명되었기 때문에, 이론적 불완전성을 커버할 수 있다고 생각한 것 같다…(공부 더 필요.. 또르르) sidenote: 모든 image의 평균 image는 무엇인가?이건 겻님이 질문했던 내용이다.unconditional로 학습할 때는 class들을 random으로 섞어서 학습한다.그렇게 학습한 모델의 아웃풋은 모든 image의 평균 image일 텐데 그게 어떻게 생겼을까?라는 게 질문의 요지였다.사실상 classifier-free guidance는 특정 class의 image에서 평균 image를 빼는 방식으로 guidance를 주는 것이다.답은 output을 직접 뽑아봐야 알겠지만, 이런 식으로 생각해본 적이 없어서 흥미로운 질문이었다,, " }, { "title": "Intro - Diffusion models", "url": "/posts/review_intro/", "categories": "AI, Diffusion model", "tags": "Generative model, Diffusion model, review", "date": "2022-07-16 20:00:00 +0900", "snippet": "Diffusion model은 generative model의 대세가 되어가는 모양새이다.(뇌피셜)그런데 정말 유명한 모델이 아니면 Diffusion model에 관한 한국어 리뷰가 별로 없어서, 기왕 논문으로 세미나한 김에 정리해서 올리자고 생각했다.근데 그 생각을 한 게 5월이고 지금은 8월을 앞두고 있다,,,^^인생의 관건은 역시 실행력 아닐까?무튼 이 블로그에 올라오는 모델 리뷰는 크게 두 가지 과정을 거친다.먼저 리뷰할 논문 선정하고 스터디 한 후에, 겻님이랑 친구들 모두 참석하는 논문 세미나에서 얘기를 한다.리뷰에는 그 과정을 거치면서 스스로 정리한 내용을 담았다.논문의 A to Z 까지 질척대는 글은 아닐 것이다.만약 누군가 이 논문에 대해 묻는다면 꼭 알려줘야지 싶은 내용만 읽기 편하게 압축했다.세미나에서 PPT를 활용하는데, 그 PPT는 내가 이해한 한도 안에서 흐름과 내용을 집약해놓은 것이다.다시말해 PPT가 곧 인생 최대 이해치이다.그래서 리뷰에서도 PPT 담긴 내용을 차례로 짚어가며 설명을 풀어나갈 예정이다!디퓨전 모델 세미나를 갑자기 던져준 겻님, 같이 공부한 디퓨젼 모델 스터디원들, 같이 글쓰는 ssbae, ebcho 모두 고마워~~" }, { "title": "디퓨젼 모델 리뷰 계획!!(A review plan for diffusion models)", "url": "/posts/A-review-plan-for-diffusion-models-copy/", "categories": "AI, Diffusion model", "tags": "Generative model, Diffusion model, review", "date": "2022-07-16 20:00:00 +0900", "snippet": "writers! reviewer homepage ssbae https://seongsubae.info/ mjlee https://mjbooo.github.io/ ebcho https://eunbyeol-cho.github.io/ paper list! # Date Reviewer Title 1 22-07-29 mjlee Classifier-Free Diffusion Guidance (Ho et al., 2021) 2 22-08-05 ssbae Diffusion-LM Improves Controllable Text Generation (XL Li et al., 2022) 3 22-09-20 mjlee [Structured Denoising Diffusion Models in Discrete State-Spaces (Ho et al., 2021)] 후보들Improved Denoising Diffusion Probabilistic Models (Nichol et al., 2021) DDPM에 몇 가지 modification을 더해서 높은 log-likelihood, 안정적인 학습 양상을 얻었음을 주장하는 논문 Introducing Improved DDPM which can be stably trained and achieve high log-likelihood by adding few modifications to DDPM) https://arxiv.org/abs/2102.09672Classifier-Free Diffusion Guidance (Ho et al., 2021) Diffusion Models Beat GANs on Image Synthesis에서 수행한 classifier-guidance를 pre-trained classifier 없이도 (classifier-free) 수행할 수 있음을 보인 논문 Introducing classifier-free guidance which can perform the functionality of classifier-guidance without the pre-trained classifier, necessitated in previous paper ‘Diffusion Models Beat GANs on Image Synthesis’ https://openreview.net/forum?id=qw8AKxfYbIStructured Denoising Diffusion Models in Discrete State-Spaces (Ho et al., 2021) 기존 Multinomial diffusion model을 generalize시킴으로써 discrete state space에서 더 잘 작동하게 된 diffusion model (D3PM)을 선보인 논문 Introducing Discrete Denoising Diffusion Probabilistic Model (D3PM) which works better in discrete state space as it generalizes the existing multinomial diffusion model. https://openreview.net/forum?id=h7-XixPCALImagen TBC..Glide (?) TBC..High-Resolution Image Synthesis with Latent Diffusion Models: Diffusion for latent vectors TBC..Diffusion Autoencoders: Toward a Meaningful and Decodable Representation TBC.." }, { "title": "Hello (github.io) world!", "url": "/posts/hello-(github.io)-world!/", "categories": "Note", "tags": "Note", "date": "2022-07-16 18:00:00 +0900", "snippet": "I’m getting used to this!" }, { "title": "Writing a New Post", "url": "/posts/write-a-new-post/", "categories": "", "tags": "", "date": "2019-08-08 15:10:00 +0900", "snippet": "This post will guide you how to write a post on Chirpy theme. Even if you have previous experience with Jekyll, this article is worth reading, because many features require specific variables to be set.Naming and PathCreate a new file named YYYY-MM-DD-TITLE.EXTENSION and put it in the _posts of the root directory. Please note that the EXTENSION must be one of md and markdown. If you want to save time of creating files, please consider using the plugin Jekyll-Compose to accomplish this.Front MatterBasically, you need to fill the Front Matter as below at the top of the post:---title: TITLEdate: YYYY-MM-DD HH:MM:SS +/-TTTTcategories: [TOP_CATEGORIE, SUB_CATEGORIE]tags: [TAG] # TAG names should always be lowercase--- The posts’ layout has been set to post by default, so there is no need to add the variable layout in the Front Matter block.Timezone of DateIn order to accurately record the release date of a post, you should not only set up the timezone of _config.yml but also provide the post’s timezone in variable date of its Front Matter block. Format: +/-TTTT, e.g. +0800.Categories and TagsThe categories of each post are designed to contain up to two elements, and the number of elements in tags can be zero to infinity. For instance:---categories: [Animal, Insect]tags: [bee]---Author InformationThe author information of the post usually does not need to be filled in the Front Matter , they will be obtained from variables social.name and the first entry of social.links of the configuration file by default. But you can also override it as follows:Add author information in _data/authors.yml (If your website doesn’t have this file, don’t hesitate to create one.)&lt;author_id&gt;: name: &lt;full name&gt; twitter: &lt;twitter_of_author&gt; url: &lt;homepage_of_author&gt;And then set up the custom author in the post’s YAML block:---author: &lt;author_id&gt;--- Another benefit of reading the author information from the file _data/authors.yml is that the page will have the meta tag twitter:creator, which enriches the Twitter Cards and is good for SEO.Table of ContentsBy default, the Table of Contents (TOC) is displayed on the right panel of the post. If you want to turn it off globally, go to _config.yml and set the value of variable toc to false. If you want to turn off TOC for a specific post, add the following to the post’s Front Matter:---toc: false---CommentsThe global switch of comments is defined by variable comments.active in the file _config.yml. After selecting a comment system for this variable, comments will be turned on for all posts.If you want to close the comment for a specific post, add the following to the Front Matter of the post:---comments: false---MathematicsFor website performance reasons, the mathematical feature won’t be loaded by default. But it can be enabled by:---math: true---MermaidMermaid is a great diagrams generation tool. To enable it on your post, add the following to the YAML block:---mermaid: true---Then you can use it like other markdown languages: surround the graph code with ```mermaid and ```.ImagesCaptionAdd italics to the next line of an image，then it will become the caption and appear at the bottom of the image:![img-description](/path/to/image)_Image Caption_SizeIn order to prevent the page content layout from shifting when the image is loaded, we should set the width and height for each image:![Desktop View](/assets/img/sample/mockup.png){: width=\"700\" height=\"400\" }Starting from Chirpy v5.0.0, height and width support abbreviations (height → h, width → w). The following example has the same effect as the above:![Desktop View](/assets/img/sample/mockup.png){: w=\"700\" h=\"400\" }PositionBy default, the image is centered, but you can specify the position by using one of the classes normal, left, and right. Once the position is specified, the image caption should not be added. Normal position Image will be left aligned in below sample: ![Desktop View](/assets/img/sample/mockup.png){: .normal } Float to the left ![Desktop View](/assets/img/sample/mockup.png){: .left } Float to the right ![Desktop View](/assets/img/sample/mockup.png){: .right } ShadowThe screenshots of the program window can be considered to show the shadow effect, and the shadow will be visible in the light mode:![Desktop View](/assets/img/sample/mockup.png){: .shadow }CDN URLIf you host the images on the CDN, you can save the time of repeatedly writing the CDN URL by assigning the variable img_cdn of _config.yml file:img_cdn: https://cdn.comOnce img_cdn is assigned, the CDN URL will be added to the path of all images (images of site avatar and posts) starting with /.For instance, when using images:![The flower](/path/to/flower.png)The parsing result will automatically add the CDN prefix https://cdn.com before the image path:&lt;img src=\"https://cdn.com/path/to/flower.png\" alt=\"The flower\"&gt;Image PathWhen a post contains many images, it will be a time-consuming task to repeatedly define the path of the images. To solve this, we can define this path in the YAML block of the post:---img_path: /img/path/---And then, the image source of Markdown can write the file name directly:![The flower](flower.png)The output will be:&lt;img src=\"/img/path/flower.png\" alt=\"The flower\"&gt;Preview ImageIf you want to add an image to the top of the post contents, specify the attribute path, width, height, and alt for the image:---image: path: /path/to/image/file width: 1000 # in pixels height: 400 # in pixels alt: image alternative text---Except for alt, all other options are necessary, especially the width and height, which are related to user experience and web page loading performance. The above section “Size” also mentions this.Starting from Chirpy v5.0.0, the attributes height and width can be abbreviated: height → h, width → w. In addition, the img_path can also be passed to the preview image, that is, when it has been set, the attribute path only needs the image file name.Starting from Chirpy v5.2.0, the property for the preview image is changed to image.path. If upgrading the theme from a prior version, you will have to update posts’ metadata to use new image property.Pinned PostsYou can pin one or more posts to the top of the home page, and the fixed posts are sorted in reverse order according to their release date. Enable by:---pin: true---PromptsThere are several types of prompts: tip, info, warning, and danger. They can be generated by adding the class prompt-{type} to the blockquote. For example, define a prompt of type info as follows:&gt; Example line for prompt.{: .prompt-info }SyntaxInline Code`inline code part`Filepath Hightlight`/path/to/a/file.extend`{: .filepath}Code BlockMarkdown symbols ``` can easily create a code block as follows:```This is a plaintext code snippet.```Specifying LanguageUsing ```{language} you will get a code block with syntax highlight:```yamlkey: value``` The Jekyll tag {% highlight %} is not compatible with this theme.Line NumberBy default, all languages except plaintext, console, and terminal will display line numbers. When you want to hide the line number of a code block, add the class nolineno to it:```shellecho 'No more line numbers!'```{: .nolineno }Specifying the FilenameYou may have noticed that the code language will be displayed at the top of the code block. If you want to replace it with the file name, you can add the attribute file to achieve this:```shell# content```{: file=\"path/to/file\" }Liquid CodesIf you want to display the Liquid snippet, surround the liquid code with {% raw %} and {% endraw %}:{% raw %}```liquid{% if product.title contains 'Pack' %} This product's title contains the word Pack.{% endif %}```{% endraw %}Or adding render_with_liquid: false (Requires Jekyll 4.0 or higher) to the post’s YAML block.Learn MoreFor more knowledge about Jekyll posts, visit the Jekyll Docs: Posts." } ]
